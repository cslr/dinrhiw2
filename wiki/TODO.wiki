#summary misc detailed notes what to do (short-term internal dev)

LIST:

  * make all initialization codes (LBFGS, BFGS, NNGradDescent) to use PCA-prepriming, THEORY: should we calculate E[g(x)] term differently?
  * *implement FastPCA*: https://maxwell.ict.griffith.edu.au/spl/publications/papers/prl07_alok_pca.pdf - this is needed for ultradeep algorithm (if does make sense)
  * move improvements from LBFGS and "grad" to parallel versions and BFGS
  * SCALABILITY: conffile.load() cannot load large networks
  * SCALABILITY: "grad" should scale to VERY LARGE dimensions and datasets
  * write job application(s)
  * increase version numbers
  * merge nntool and datatool
  * create statically linked nntool (compress using upx) and distribute it
  * create shared-libraries too and link to them as a default
  * implement perfect forwarding of rvalues in linear algebra (matrix/vertex operators) in dinrhiw

FURTHER TEST asinh(x) non-linearity. This time with time-series signals.