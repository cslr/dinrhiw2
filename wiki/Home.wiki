#summary Read me first

The library was originally developed during 1998-2005. There is no plans to develop the private library any further and this is the official fork of the library to be LGPL-licensed code (2014). The primary aim of the library is to provide machine learning tools for *[https://sourceforge.net/projects/resonanz/ Resonanz]* project.

Machine learning component contains: 

  * unix commands line tools to do machine learning from scripts (nntool, dstool)
  * multistart L-BFGS neural network 2nd order optimizer
  * basic BayesianNeuralNetwork using adaptive hybrid monte carlo sampling
  * principal component analysis (PCA) and independent component analysis (ICA) preprocessing methods
  * multistart gradient descent optimizer for neural networks
  * multi-threaded (multicore CPUs) code to support parallel search

Additionally, the library contains basic linear algebra and various other general computer science algorithms like radix sorting (for floating point numbers through conversion code O(N)), hermite curve interpolation and cryptography (AES, DES..). The compiler used is GCC <https://gcc.gnu.org/> and the build process uses GNU Makefile and autoconf. The library also uses few C++11 features meaning that only the newest GCC C++ compilers are likely to work. 

*CompilationInstructions*

== LICENSE ==

LGPL license. Links with BSD-style libraries (zlib, gmp and blas).

Afaik. G++ runtime exception should allow C++ code to be LGPL library instead of GPL.

== PLAN ==

There are no current plans to add new functionality but to do proper testing and bugfixing. If someone has motivation and time, implementing advanced methods like deep boltzmann machines and variational bayesian methods would be interesting. 

== DOCUMENTATION ==

class nnetwork<>

class dataset<>

class BFGS<>

class BFGS_nnetwork<> (neural network BFGS optimizer)

class NNGradDescent<> (parallel neural network gradient descent)

class HMC<> (parallel hamiltonian monte carlo sampling for neural networks)

tools/nntool

tools/dstool


are the primary classes and tools to look at and use. Also read HowToLearnFromData page.

== TODO ==

  * cleanup the code and remove classes that are not needed and don't belong to this library
  * optimize and implement L-BFGS code and write parallel search code (random starting points)
  * DOCUMENTATION, bug fixing
  * the use of BLAS libraries for GPUs to make things faster (NVIDIA CUDA and cuBLAS) - currently the library uses generic BLAS for matrix operations
  * try to remove few x86 dependencies (cpuid instruction)


There are better free libraries available so there is no much point in developing this library much further (except from the point of enough competition which keeps OS model working). However, development of *nntool* and other command-line tools to do *machine learning using shell scripts is maybe interesting*. To support this *nntool* and *dstool* command line tools should be developed as easy to use from command line as possible.

== PLATFORMS ==

The software has been developed in Linux (x86 and amd64). It compiles with MINGW/Windows compiler but crashes because of strange bugs. It has been reported to work correctly in Cygwin 32bit environment (but cygwin license is a problem). Currently there are few x86 specific instructions (CPUID) and assumptions (size of int and float etc) so only x86 and amd64/x86_64 are fully supported.

== DONATE ==

If you like this software and want it to be successful, please [https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=7SH2EQU7RAY82 donate money].

== CONTACT DETAILS ==

Tomas Ukkonen [mailto:tomas.ukkonen@iki.fi]