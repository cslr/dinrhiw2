TODO

Neuromancer/Resonanz Requirements:
* HMM, GB-RBM and BB-RBM

  - implement discrete HMM and using arbitrary precision numbers
    * study some Hidden Markov Model theory
    * this will be used to learn and generate likely stimulation sequences
      and tag stimulation elements into language (does make sense?)
      
   - implement BB-RBM as well from the theory as GB-RBM 
   - implement stacked autoencoder GB-RBM (input) + BB-RBM for pictures
   
========================

- bayesian neural network fixes 
  (train both function and its inverse at the same time)

- OPTIMIZE BFGS for speed:
  * implement L-BFGS for large neural networks
    (in practice we ALWAYS have rank(H) << dim(H)
     so there is no point in trying to estimate the whole H)
  
- HMC sampler:
  [check convergence by starting N sampling threads and
   then sample until ||m_w_j - m_x_i|| converges close
   enough to zero] (mean values are close enough each other)

- GA3, ga3_test_function.h: fully implement and test
  genetic algorithm optimization for real-valued vectors.
  - change GA implementation to sort offspring and select
    the better upper part (radix sort) (+ some randomness)

- write configure script to detect existence of
  NVIDIA BLAS-library and use it if it exists instead of generic
  BLAS-library (should work on my new laptop)

- there are bugs in classes that create internal pthreads to do
  background execution. the pthread-entry functions are not
  templated to do proper pointer casts (to templated pointer type)

- bugfix and debugging:
  * valgrind, gdb

- make it compile cleanly under MinGW

- write configure scripts to use SSE instructions
  if they are detected by the scripts

- BIG TASK: implement RBM deep belief networks (deep learning) code
  * implement NN learning using initial unsupervised learning step

- DOCUMENTATION

----------------------------------------------------------------
OLD TODO

  - AMD64 MATH: SYLVESTER EQ SOLVER FAIL

  TEST
   - write TEST to test gramschmidt<>(vector) gives same as gramschimidt<>(matrix)
   - test dataset::convert()     
   - GDA clustering
   - retest matrix inversion code after bugfix
  test association rule finder with real data
  test datamining code


(MAYBE) BUGS/ERRORS

  avl-tree remove_node() has serious bugs:
    avl-tree infinite loops
    avl-tree forgots/drops non-removed nodes (bad)
    avl-tree isn't balanced after removal of nodes (bug).
    (calculate with paper&pencil with small examples..)

  test and/or add accuracy of symmetric eigenvalue solver
  (PCA seems to fail sometimes)

  write faster/good association rules finder (reread the relevant paper)
  - what other datamining methods would be needed/useful(?)
  - copy from own Java code

===================================================================
